{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVlD239erCBg",
    "outputId": "983977b8-6fa6-4ae7-f2e8-dd6433b4a3fc"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "R3B94YDzrDtD"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/COVID19/covid-19-mrna-vaccine-degradation/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PIWfLPMYsPU_"
   },
   "outputs": [],
   "source": [
    "def MCRMSE_numpy(y_true, y_pred):\n",
    "    colwise_mse = np.mean(np.square(y_true - y_pred), axis=1)\n",
    "    return np.mean(np.sqrt(colwise_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FUFR43AVtYuP"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['id_seqpos'], key=lambda x: x.str.extract(r'_(\\d+)$').astype(int).iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b63-nQZBtbYI"
   },
   "outputs": [],
   "source": [
    "# train_inputs = preprocess_inputs(df, token2int, input_columns)\n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "df['sequence']= label_encoder.fit_transform(df['sequence']) \n",
    "df['structure']= label_encoder.fit_transform(df['structure']) \n",
    "df['predicted_loop_type']= label_encoder.fit_transform(df['predicted_loop_type']) \n",
    "df['b1_sequence']= label_encoder.fit_transform(df['b1_sequence']) \n",
    "df['b2_sequence']= label_encoder.fit_transform(df['b2_sequence']) \n",
    "df['b3_sequence']= label_encoder.fit_transform(df['b3_sequence']) \n",
    "df['b4_sequence']= label_encoder.fit_transform(df['b4_sequence']) \n",
    "df['b5_sequence']= label_encoder.fit_transform(df['b5_sequence']) \n",
    "df['b1_structure']= label_encoder.fit_transform(df['b1_structure']) \n",
    "df['b2_structure']= label_encoder.fit_transform(df['b2_structure']) \n",
    "df['b3_structure']= label_encoder.fit_transform(df['b3_structure'])\n",
    "df['b4_structure']= label_encoder.fit_transform(df['b4_structure'])\n",
    "df['b5_structure']= label_encoder.fit_transform(df['b5_structure'])\n",
    "df['b1_predicted_loop_type']= label_encoder.fit_transform(df['b1_predicted_loop_type'])\n",
    "df['b2_predicted_loop_type']= label_encoder.fit_transform(df['b2_predicted_loop_type'])\n",
    "df['b3_predicted_loop_type']= label_encoder.fit_transform(df['b3_predicted_loop_type'])\n",
    "df['b4_predicted_loop_type']= label_encoder.fit_transform(df['b4_predicted_loop_type'])\n",
    "df['b5_predicted_loop_type']= label_encoder.fit_transform(df['b5_predicted_loop_type'])\n",
    "df['a1_sequence']= label_encoder.fit_transform(df['a1_sequence']) \n",
    "df['a2_sequence']= label_encoder.fit_transform(df['a2_sequence']) \n",
    "df['a3_sequence']= label_encoder.fit_transform(df['a3_sequence']) \n",
    "df['a4_sequence']= label_encoder.fit_transform(df['a4_sequence']) \n",
    "df['a5_sequence']= label_encoder.fit_transform(df['a5_sequence']) \n",
    "df['a1_structure']= label_encoder.fit_transform(df['a1_structure']) \n",
    "df['a2_structure']= label_encoder.fit_transform(df['a2_structure']) \n",
    "df['a3_structure']= label_encoder.fit_transform(df['a3_structure'])\n",
    "df['a4_structure']= label_encoder.fit_transform(df['a4_structure'])\n",
    "df['a5_structure']= label_encoder.fit_transform(df['a5_structure'])\n",
    "df['a1_predicted_loop_type']= label_encoder.fit_transform(df['a1_predicted_loop_type'])\n",
    "df['a2_predicted_loop_type']= label_encoder.fit_transform(df['a2_predicted_loop_type'])\n",
    "df['a3_predicted_loop_type']= label_encoder.fit_transform(df['a3_predicted_loop_type'])\n",
    "df['a4_predicted_loop_type']= label_encoder.fit_transform(df['a4_predicted_loop_type'])\n",
    "df['a5_predicted_loop_type']= label_encoder.fit_transform(df['a5_predicted_loop_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kwB7Xf13tdq2"
   },
   "outputs": [],
   "source": [
    "X = df.drop(['id','id_seqpos','reactivity','deg_Mg_pH10','deg_Mg_50C'],axis=1)\n",
    "y = df[['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "C4Uv1ioJtgma"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split , KFold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.27, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lH2_Dfx5IS6p",
    "outputId": "79398a95-9dbc-4b67-9c4f-44cf29566e82"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "# def hyperParameterTuning(X_train, y_train):\n",
    "#     param_tuning = {\n",
    "#         'learning_rate': [0.01, 0.1],\n",
    "#         'max_depth': [3, 5, 7, 10],\n",
    "#         'min_child_weight': [1, 3, 5],\n",
    "#         'subsample': [0.5, 0.7],\n",
    "#         'colsample_bytree': [0.5, 0.7],\n",
    "#         'n_estimators' : [100, 200, 500],\n",
    "#         'objective': ['reg:squarederror']\n",
    "#     }\n",
    "\n",
    "#     xgb_model = XGBRegressor()\n",
    "\n",
    "#     gsearch = GridSearchCV(estimator = xgb_model,\n",
    "#                            param_grid = param_tuning,                        \n",
    "#                            #scoring = 'neg_mean_absolute_error', #MAE\n",
    "#                            #scoring = 'neg_mean_squared_error',  #MSE\n",
    "#                            cv = 5,\n",
    "#                            n_jobs = -1,\n",
    "#                            verbose = 1)\n",
    "\n",
    "#     gsearch.fit(X_train,y_train)\n",
    "\n",
    "#     return gsearch.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "regr = MultiOutputRegressor(SVR(C=1.0, epsilon=0.2))\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "print(\"MCRMSE score on test set:\", MCRMSE_numpy(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x3sHJQuAtpL4",
    "outputId": "9222fb37-ffca-4bff-a12b-1dfbd47b7816"
   },
   "outputs": [],
   "source": [
    "#MCRMSE_numpy(y_test,y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s69fe5U6hUVN",
    "outputId": "bdb1018e-8f83-4e90-9197-36e4c6ee1627"
   },
   "outputs": [],
   "source": [
    "#xgb_model.score(X_train,y_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4iA-9-xviFpC",
    "outputId": "ea25dc41-c68b-44a9-c769-a3127ea5bc8c"
   },
   "outputs": [],
   "source": [
    "#xgb_model.score(X_test,y_test) * 100\n",
    "#xgb_model.score(X_train,y_train) * 100"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "gGrw_YzcqpF9"
   },
   "source": [
    " from sklearn import datasets, ensemble\n",
    " from xgboost import XGBRegressor\n",
    " from sklearn.multioutput import MultiOutputRegressor\n",
    " model = MultiOutputRegressor(XGBRegressor(max_depth=7,learning_rate=0.25)).fit(X_train, y_train)\n",
    " y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "iaXorUe1NI4_"
   },
   "source": [
    " print(MCRMSE_numpy(y_test,y_pred))\n",
    " print(model.score(X_train,y_train) * 100)\n",
    " print(model.score(X_test,y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Dv4eP-v9lVTT"
   },
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "#data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n",
    "#params = {'objective':'binary:logistic','eval_metric':'logloss',\n",
    "  #        'eta':0.01,\n",
    " #         'subsample':0.1}\n",
    "#xgb_cv = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5, metrics = 'logloss',seed=42) \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1JYAu4aslpb2"
   },
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as ltb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import datasets, ensemble\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the estimator for feature selection (e.g. Linear Regression)\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=KFold(n_splits=3))\n",
    "\n",
    "# Fit the feature selector on the training data\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features: \", X_train.columns[selector.support_])\n",
    "\n",
    "# Train a LightGBM model using the selected features\n",
    "model_lgbm = MultiOutputRegressor(ltb.LGBMRegressor())\n",
    "model_lgbm.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the testing data using the LightGBM model\n",
    "y_pred_lgbm = model_lgbm.predict(X_test_selected)\n",
    "print(\"LightGBM MCRMSE: \", MCRMSE_numpy(y_test, y_pred_lgbm))\n",
    "\n",
    "# Train an XGBoost model using the selected features\n",
    "model_xgb = MultiOutputRegressor(XGBRegressor(max_depth=7, learning_rate=0.2))\n",
    "model_xgb.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the testing data using the XGBoost model\n",
    "y_pred_xgb = model_xgb.predict(X_test_selected)\n",
    "print(\"XGBoost MCRMSE: \", MCRMSE_numpy(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from statsmodels.regression.linear_model import OLS\n",
    "\n",
    "bestModelsForEachIteration = []\n",
    "inputVariablesNames = list(X.columns)\n",
    "quantityOfInputVariables = len(inputVariablesNames)\n",
    "selectedVariables = []\n",
    "selectedAIC = []\n",
    "\n",
    "\n",
    "for iteration in range(quantityOfInputVariables):\n",
    "    bestCurrentModel = None\n",
    "    LowestCurrentAIC = 1e8\n",
    "    bestCurrentVariable = None\n",
    "    for inputVariableName in inputVariablesNames:\n",
    "        # fit model\n",
    "        regr_model = OLS(y, X[selectedVariables + [inputVariableName]]).fit()\n",
    "        # get the aic value\n",
    "        aic_model = regr_model.aic\n",
    "        # assign lowest aic_value and corresponding model and variables\n",
    "        if aic_model <= LowestCurrentAIC:\n",
    "            bestCurrentModel = regr_model\n",
    "            bestCurrentVariable = inputVariableName\n",
    "            LowestCurrentAIC = aic_model\n",
    "    # put the best parameters(aci,variables, model) into the corresponding list\n",
    "    bestModelsForEachIteration.append(bestCurrentModel)\n",
    "    selectedAIC.append(LowestCurrentAIC)\n",
    "    selectedVariables.append(bestCurrentVariable)\n",
    "    # remove the selected variable\n",
    "    inputVariablesNames.remove(bestCurrentVariable)\n",
    "    print('Iteration: ', iteration, 'Selected Variables: ', selectedVariables, 'Lowest AIC:', selectedAIC)\n",
    "\n",
    "# choose the lowest_aic_value model\n",
    "bestmodel_index_forward = selectedAIC.index(min(selectedAIC))\n",
    "bestmodel_model_forward = bestModelsForEachIteration[bestmodel_index_forward]\n",
    "bestmodel_variable_forward = selectedVariables[: bestmodel_index_forward+1]\n",
    "fifth_variable = selectedVariables[4]\n",
    "print(\"bestmodel_index:\", bestmodel_index_forward, \"bestmodel_variables:\",bestmodel_variable_forward)\n",
    "print(\"fifth_variable:\",fifth_variable)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "import math\n",
    "import copy\n",
    "\n",
    "bestModelsForEachIteration = []\n",
    "inputVariablesNames = list(X_train.columns)\n",
    "quantityOfInputVariables = len(inputVariablesNames)\n",
    "removedRMSE = []\n",
    "variable_lists = []\n",
    "\n",
    "for iteration in range(quantityOfInputVariables):\n",
    "    bestCurrentModel = None\n",
    "    LowestCurrentRMSE = 1e8\n",
    "    bestCurrentVariable = None\n",
    "    # first step: no removed variables\n",
    "    if iteration == 0:\n",
    "        # fit model\n",
    "        regr_model = OLS(y_train, X_train[inputVariablesNames]).fit()\n",
    "        # predict\n",
    "        l_preds=regr_model.predict(X_test[inputVariablesNames])\n",
    "        #evaluate our model's performance using root of mean squared error\n",
    "        mse=mean_squared_error(y_test,l_preds)\n",
    "        rmse=math.sqrt(mse)\n",
    "        # assign lowest aic_value and corresponding model and variables\n",
    "        if rmse <= LowestCurrentRMSE:\n",
    "            bestCurrentModel = regr_model\n",
    "            bestCurrentVariable = None\n",
    "            LowestCurrentRMSE = rmse\n",
    "    # if not first step, remove one variable\n",
    "    else:\n",
    "        for inputVariableName in inputVariablesNames:\n",
    "            copyVariables = copy.deepcopy(inputVariablesNames)\n",
    "            copyVariables.remove(inputVariableName)\n",
    "            # fit model\n",
    "            regr_model = OLS(y_train, X_train[copyVariables]).fit()\n",
    "            # predict\n",
    "            l_preds=regr_model.predict(X_test[copyVariables])\n",
    "            #evaluate our model's performance using mean squared error\n",
    "            mse=mean_squared_error(y_test,l_preds)\n",
    "            rmse=math.sqrt(mse)\n",
    "            # assign lowest aic_value and corresponding model and variables\n",
    "            if rmse <= LowestCurrentRMSE:\n",
    "                bestCurrentModel = regr_model\n",
    "                bestCurrentVariable = inputVariableName\n",
    "                LowestCurrentRMSE = rmse\n",
    "    # put the best parameters(aci,variables, model) into the corresponding list\n",
    "    bestModelsForEachIteration.append(bestCurrentModel)\n",
    "    removedRMSE.append(LowestCurrentRMSE)\n",
    "    # if not first step, remove one variable\n",
    "    if bestCurrentVariable:\n",
    "        inputVariablesNames.remove(bestCurrentVariable)\n",
    "        variable_list = copy.deepcopy(inputVariablesNames)\n",
    "        variable_lists.append(variable_list)\n",
    "    print('Iteration: ', iteration, 'Selected Variables: ', inputVariablesNames, 'Lowest RMSE:', removedRMSE)\n",
    "# choose the lowest_aic_value model\n",
    "bestmodel_index_backward = removedRMSE[-5:].index(min(removedRMSE[-5:]))\n",
    "bestmodel_model_backward = bestModelsForEachIteration[-5:][bestmodel_index_backward]\n",
    "bestmodel_variable_backward = variable_lists[-5:][bestmodel_index_backward]\n",
    "print(\"bestmodel_index:\", bestmodel_index_backward, \"bestmodel_variables:\",bestmodel_variable_backward)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "bestmodel_index_backward_nl = removedRMSE.index(min(removedRMSE))\n",
    "bestmodel_model_backward_nl = bestModelsForEachIteration[bestmodel_index_backward_nl]\n",
    "bestmodel_variable_backward_nl = variable_lists[bestmodel_index_backward_nl]\n",
    "print(\"bestmodel_index:\", bestmodel_index_backward_nl, \"bestmodel_variables:\",bestmodel_variable_backward_nl)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(\"bestmodel_variable_forward:\", bestmodel_variable_forward)\n",
    "print(\"bestmodel_variable_backward:\", bestmodel_variable_backward_nl)\n",
    "# get the intersection of two best models(forward-stepwise and backward-stepwise)\n",
    "intersection_variables = set(bestmodel_variable_forward).intersection(set(bestmodel_variable_backward_nl))\n",
    "print('intersection_variables:', intersection_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['a1_predicted_loop_type', 'b1_sequence', 'deg_error_Mg_50C', 'sequence', 'b3_structure', 'deg_error_pH10', 'b5_predicted_loop_type', 'a4_sequence', 'a3_sequence', 'b5_structure', 'deg_pH10', 'b1_predicted_loop_type', 'a5_structure', 'deg_error_50C', 'a1_structure', 'deg_50C', 'b4_structure', 'a3_predicted_loop_type', 'a1_sequence', 'b2_structure', 'a2_sequence', 'structure', 'a4_structure', 'a4_predicted_loop_type', 'b3_sequence', 'b1_structure', 'b4_predicted_loop_type', 'deg_error_Mg_pH10', 'b2_predicted_loop_type', 'b5_sequence', 'a5_predicted_loop_type', 'reactivity_error', 'predicted_loop_type', 'a2_predicted_loop_type', 'a5_sequence', 'b4_sequence']]\n",
    "y = df[['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersection\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features:  Index(['a1_predicted_loop_type', 'b1_sequence', 'deg_error_Mg_50C', 'sequence',\n",
      "       'b3_structure', 'deg_error_pH10', 'b5_predicted_loop_type',\n",
      "       'a4_sequence', 'a3_sequence', 'b5_structure', 'deg_pH10',\n",
      "       'b1_predicted_loop_type', 'a5_structure', 'deg_error_50C',\n",
      "       'a1_structure', 'deg_50C', 'b4_structure', 'a3_predicted_loop_type',\n",
      "       'a1_sequence', 'b2_structure', 'a2_sequence', 'structure',\n",
      "       'a4_structure', 'a4_predicted_loop_type', 'b3_sequence', 'b1_structure',\n",
      "       'b4_predicted_loop_type', 'deg_error_Mg_pH10', 'b2_predicted_loop_type',\n",
      "       'b5_sequence', 'a5_predicted_loop_type', 'reactivity_error',\n",
      "       'predicted_loop_type', 'a2_predicted_loop_type', 'a5_sequence',\n",
      "       'b4_sequence'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "import lightgbm as ltb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn import datasets, ensemble\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define the estimator for feature selection (e.g. Linear Regression)\n",
    "estimator = LinearRegression()\n",
    "selector = RFECV(estimator, step=1, cv=KFold(n_splits=5))\n",
    "\n",
    "# Fit the feature selector on the training data\n",
    "selector.fit(X_train, y_train)\n",
    "X_train_selected = selector.transform(X_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Print the selected features\n",
    "print(\"Selected Features: \", X_train.columns[selector.support_])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost MCRMSE:  0.15478737999478112\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train an XGBoost model using the selected features\n",
    "model_xgb = MultiOutputRegressor(XGBRegressor(learning_rate=0.2,max_depth=8,max_bin=310,n_estimators=10000))\n",
    "model_xgb.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the testing data using the XGBoost model\n",
    "y_pred_xgb = model_xgb.predict(X_test_selected)\n",
    "print(\"XGBoost MCRMSE: \", MCRMSE_numpy(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "\n",
    "# Define the XGBoost model\n",
    "model_xgb = MultiOutputRegressor(XGBRegressor(learning_rate=0.2, n_estimators=10000))\n",
    "\n",
    "# Get the learning curve for the XGBoost model\n",
    "train_sizes, train_scores, test_scores = learning_curve(model_xgb, X_train_selected, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "train_scores_mean = -np.mean(train_scores, axis=1)\n",
    "test_scores_mean = -np.mean(test_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve for the XGBoost model\n",
    "plt.plot(train_sizes, train_scores_mean, label='Training Error')\n",
    "plt.plot(train_sizes, test_scores_mean, label='Validation Error')\n",
    "plt.title('XGBoost Learning Curve')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.score(X_train,y_train) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.score(X_test,y_test) * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lgbm.score(X_train,y_train) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_lgbm.score(X_test,y_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G0OxBpmdtiiB"
   },
   "outputs": [],
   "source": [
    "# import lightgbm as ltb\n",
    "# from sklearn.multioutput import MultiOutputRegressor\n",
    "# model = MultiOutputRegressor(ltb.LGBMRegressor(learning_rate=0.11,num_leaves=130,max_depth=12\n",
    "#                                                ,feature_fraction=0.9,max_bin=310,)).fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "utEXNBf2-zSw"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('C:/Users/COVID19/covid-19-mrna-vaccine-degradation/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hS69ljWttiF"
   },
   "outputs": [],
   "source": [
    "# train_inputs = preprocess_inputs(df, token2int, input_columns)\n",
    "from sklearn import preprocessing\n",
    "# label_encoder object knows how to understand word labels. \n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "# Encode labels in column 'Country'. \n",
    "test['sequence']= label_encoder.fit_transform(test['sequence']) \n",
    "test['structure']= label_encoder.fit_transform(test['structure']) \n",
    "test['predicted_loop_type']= label_encoder.fit_transform(test['predicted_loop_type']) \n",
    "test['b1_sequence']= label_encoder.fit_transform(test['b1_sequence']) \n",
    "test['b2_sequence']= label_encoder.fit_transform(test['b2_sequence']) \n",
    "test['b3_sequence']= label_encoder.fit_transform(test['b3_sequence']) \n",
    "test['b4_sequence']= label_encoder.fit_transform(test['b4_sequence']) \n",
    "test['b5_sequence']= label_encoder.fit_transform(test['b5_sequence']) \n",
    "test['b1_structure']= label_encoder.fit_transform(test['b1_structure']) \n",
    "test['b2_structure']= label_encoder.fit_transform(test['b2_structure']) \n",
    "test['b3_structure']= label_encoder.fit_transform(test['b3_structure'])\n",
    "test['b4_structure']= label_encoder.fit_transform(test['b4_structure'])\n",
    "test['b5_structure']= label_encoder.fit_transform(test['b5_structure'])\n",
    "test['b1_predicted_loop_type']= label_encoder.fit_transform(test['b1_predicted_loop_type'])\n",
    "test['b2_predicted_loop_type']= label_encoder.fit_transform(test['b2_predicted_loop_type'])\n",
    "test['b3_predicted_loop_type']= label_encoder.fit_transform(test['b3_predicted_loop_type'])\n",
    "test['b4_predicted_loop_type']= label_encoder.fit_transform(test['b4_predicted_loop_type'])\n",
    "test['b5_predicted_loop_type']= label_encoder.fit_transform(test['b5_predicted_loop_type'])\n",
    "test['a1_sequence']= label_encoder.fit_transform(test['a1_sequence']) \n",
    "test['a2_sequence']= label_encoder.fit_transform(test['a2_sequence']) \n",
    "test['a3_sequence']= label_encoder.fit_transform(test['a3_sequence']) \n",
    "test['a4_sequence']= label_encoder.fit_transform(test['a4_sequence']) \n",
    "test['a5_sequence']= label_encoder.fit_transform(test['a5_sequence']) \n",
    "test['a1_structure']= label_encoder.fit_transform(test['a1_structure']) \n",
    "test['a2_structure']= label_encoder.fit_transform(test['a2_structure']) \n",
    "test['a3_structure']= label_encoder.fit_transform(test['a3_structure'])\n",
    "test['a4_structure']= label_encoder.fit_transform(test['a4_structure'])\n",
    "test['a5_structure']= label_encoder.fit_transform(test['a5_structure'])\n",
    "test['a1_predicted_loop_type']= label_encoder.fit_transform(test['a1_predicted_loop_type'])\n",
    "test['a2_predicted_loop_type']= label_encoder.fit_transform(test['a2_predicted_loop_type'])\n",
    "test['a3_predicted_loop_type']= label_encoder.fit_transform(test['a3_predicted_loop_type'])\n",
    "test['a4_predicted_loop_type']= label_encoder.fit_transform(test['a4_predicted_loop_type'])\n",
    "test['a5_predicted_loop_type']= label_encoder.fit_transform(test['a5_predicted_loop_type'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuAniX_BAEPF"
   },
   "outputs": [],
   "source": [
    "ID = test['id_seqpos']\n",
    "TEST = test.drop(['id_seqpos','id'],axis=1)\n",
    "a = model_xgb.predict(TEST)\n",
    "new = pd.DataFrame(a,columns=['reactivity','deg_Mg_pH10','deg_Mg_50C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57n6EDuZPDJi"
   },
   "outputs": [],
   "source": [
    "new_data = pd.concat([ID.rename('id_seqpos'),new], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kwoRADeVPF5x"
   },
   "outputs": [],
   "source": [
    "new_data.to_csv('xgboost_new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7a7X2ANxPK3u"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
